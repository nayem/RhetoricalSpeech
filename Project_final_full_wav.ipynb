{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  glob\n",
    "import  os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import  librosa\n",
    "import  librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, LSTM, GRU, Dense\n",
    "from keras.layers import Bidirectional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIRECTORY = 'dataset/'\n",
    "\n",
    "declarative_CLASS_train = 'NLP_Declarative/NLP_train_16k/*.wav'\n",
    "question_CLASS_train = 'NLP_Question/NLP_train_16k/*.wav'\n",
    "\n",
    "declarative_CLASS_test = 'NLP_Declarative/NLP_test_16k/*.wav'\n",
    "question_CLASS_test = 'NLP_Question/NLP_test_16k/*.wav'\n",
    "\n",
    "\n",
    "declarative_CLASS_val = 'NLP_Declarative/NLP_val_16k/*.wav'\n",
    "question_CLASS_val = 'NLP_Question/NLP_val_16k/*.wav'\n",
    "\n",
    "\n",
    "train_percentile = 0.8\n",
    "test_percentile = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenames_list(directory_path):\n",
    "    filename_list=[]\n",
    "    for filename in glob.glob(directory_path):\n",
    "        (filename_list.append(filename))\n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_files_list_train=filenames_list(ROOT_DIRECTORY+declarative_CLASS_train)\n",
    "ques_files_list_train=filenames_list(ROOT_DIRECTORY+question_CLASS_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_files_list_test=filenames_list(ROOT_DIRECTORY+declarative_CLASS_test)\n",
    "ques_files_list_test=filenames_list(ROOT_DIRECTORY+question_CLASS_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_files_list_val=filenames_list(ROOT_DIRECTORY+declarative_CLASS_val)\n",
    "ques_files_list_val=filenames_list(ROOT_DIRECTORY+question_CLASS_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dec_files_list_train), len(dec_files_list_test), len(dec_files_list_val))\n",
    "# print(len(ques_files_list_train), len(ques_files_list_test), len(ques_files_list_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "#     print (\"Features :\",len(X), X.shape, \"sampled at \", sample_rate, \"hz\")\n",
    "#     stft = np.abs(librosa.stft(X))\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "#     chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#     mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "#     contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "#     tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_RNN=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_audio_files(filename_list, label, Max_RNN):\n",
    "    max_len=-999999\n",
    "    Xs_train=[]\n",
    "    Xs_test=[]\n",
    "#     probability = [float(v) for v in percentiles.values()]\n",
    "    \n",
    "#     features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for e,fn in enumerate(filename_list):\n",
    "        print(e, fn)\n",
    "        mfccs = extract_mfcc(fn)\n",
    "        if len(mfccs[0])> max_len:\n",
    "            max_len=len(mfccs[0])\n",
    "        mfccs=np.pad(mfccs, [(0, 0), (0, Max_RNN-len(mfccs[0]))], mode='constant')\n",
    "        Xs_train.append(mfccs.T)\n",
    "        \n",
    "#         portion =  np.random.choice(2, 1, p=probability)\n",
    "#         if portion == 0:\n",
    "#             Xs_train.append(mfccs.T)\n",
    "#         elif portion == 1:\n",
    "#             Xs_test.append(mfccs.T)\n",
    "            \n",
    "#         print(mfccs.shape)\n",
    "#         Xs_train.append(mfccs.T)\n",
    "    #### Label for training\n",
    "    if label == 'declarative':\n",
    "        Ys_train = to_categorical(np.ones(len(Xs_train)),2)\n",
    "#         Ys_test = to_categorical(np.ones(len(Xs_test)),2)\n",
    "        \n",
    "    elif label == 'question':\n",
    "        Ys_train = to_categorical(np.zeros(len(Xs_train)),2)\n",
    "#         Ys_test = to_categorical(np.zeros(len(Xs_test)),2)\n",
    "    \n",
    "    Xs_train = np.array(Xs_train)\n",
    "#     Xs_test = np.array(Xs_test)\n",
    "    return Xs_train, Ys_train, max_len \n",
    "        \n",
    "#     for label, sub_dir in enumerate(sub_dirs):\n",
    "#         for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "#             try:\n",
    "#                 mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
    "#                 ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "#                 features = np.vstack([features,ext_features])\n",
    "#                 labels = np.append(labels, fn.split('fold')[1].split('-')[1])\n",
    "#             except:\n",
    "#                 print(\"Error processing \" + fn + \" - skipping\")\n",
    "#     return np.array(features), np.array(labels, dtype = np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mfcc vectors for declarative and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_Xs_train, dec_Ys_train, dec_max_len=parse_audio_files(dec_files_list_train, \"declarative\", Max_RNN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_Xs_test, dec_Ys_test, dec_max_len_test=parse_audio_files(dec_files_list_test, \"declarative\", Max_RNN)\n",
    "# dec_Xs_val, dec_Ys_val, dec_max_len_val=parse_audio_files(dec_files_list_val, \"declarative\", Max_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ques_Xs_train, ques_Ys_train, ques_max_len_train=parse_audio_files(ques_files_list_train, \"question\", Max_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ques_Xs_test, ques_Ys_test, ques_max_len_test=parse_audio_files(ques_files_list_test, \"question\", Max_RNN)\n",
    "# ques_Xs_val, ques_Ys_val, ques_max_len_val=parse_audio_files(ques_files_list_val, \"question\", Max_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentiles = {'train':train_percentile, 'test':test_percentile}\n",
    "# dec_Xs_train, dec_Xs_test, dec_Ys_train, dec_Ys_test, dec_max_len=parse_audio_files(percentiles, dec_files_list, \"declarative\", Max_RNN)\n",
    "\n",
    "# print(len(dec_Xs_train), len(dec_Ys_train), len(dec_Xs_test), len(dec_Ys_test), \"Max Len: \", dec_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name, vector_name):\n",
    "    ### Writing training data S\n",
    "\n",
    "    with open(file_name, 'wb') as fs:\n",
    "        for val in vector_name:\n",
    "#             print(val)\n",
    "#             sn, sr=librosa.load(fname_list[i], sr=None)\n",
    "#             Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "# #             mag_Sn=np.abs(Sn)\n",
    "#     #         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "            np.savetxt(fs, val, fmt='%.5f')\n",
    "            fs.write(b'\\n')\n",
    "    fs.close()            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"dec_Xs_val_full_mfcc.txt\", dec_Xs_val)\n",
    "write_file(\"ques_Xs_val_full_mfcc.txt\", ques_Xs_val)\n",
    "# write_file(\"train_n.txt\", fname_trn)\n",
    "# write_file(\"train_x.txt\", fname_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"dec_Xs_test_full_mfcc.txt\", dec_Xs_test)\n",
    "write_file(\"ques_Xs_test_full_mfcc.txt\", ques_Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"dec_Xs_train_full_mfcc.txt\", dec_Xs_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"ques_Xs_train_full_mfcc.txt\", ques_Xs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Reading file\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        lines=f.readlines()\n",
    "        print(len(lines))\n",
    "        sentence_full=[]\n",
    "        count = 0\n",
    "        sentence=[]\n",
    "        for line in lines:\n",
    "\n",
    "            if count < 500:\n",
    "                if count ==0:\n",
    "                    sentence=np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    count+=1\n",
    "                else:\n",
    "                    myarray = np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    sentence=np.concatenate((sentence, myarray), axis=0)\n",
    "                    count+=1\n",
    "            else:\n",
    "                sentence_full.append(sentence) \n",
    "                count=0\n",
    "                sentence=[]\n",
    "        return sentence_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332163\n",
      "383265\n"
     ]
    }
   ],
   "source": [
    "dec_Xs_val_file = read_file(\"dec_Xs_val_full_mfcc.txt\")\n",
    "ques_Xs_val_file = read_file(\"ques_Xs_val_full_mfcc.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dec_Xs_val_file), dec_Xs_val_file[0].shape)\n",
    "# print(len(ques_Xs_val_file), ques_Xs_val_file[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430856\n",
      "1379754\n"
     ]
    }
   ],
   "source": [
    "dec_Xs_test_file = read_file(\"dec_Xs_test_full_mfcc.txt\")\n",
    "ques_Xs_test_file = read_file(\"ques_Xs_test_full_mfcc.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592158\n"
     ]
    }
   ],
   "source": [
    "dec_Xs_train_file = read_file(\"dec_Xs_train_full_mfcc.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5876730\n"
     ]
    }
   ],
   "source": [
    "ques_Xs_train_file = read_file(\"ques_Xs_train_full_mfcc.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label data for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_Ys_train_file = to_categorical(np.ones(len(dec_Xs_train_file)),2)\n",
    "dec_Ys_test_file = to_categorical(np.ones(len(dec_Xs_test_file)),2)\n",
    "dec_Ys_val_file = to_categorical(np.ones(len(dec_Xs_val_file)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_Ys_train_file = to_categorical(np.zeros(len(ques_Xs_train_file)),2)\n",
    "ques_Ys_test_file = to_categorical(np.zeros(len(ques_Xs_test_file)),2)\n",
    "ques_Ys_val_file = to_categorical(np.zeros(len(ques_Xs_val_file)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dec_Xs_val_file[0].shape)\n",
    "len(dec_Xs_val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dec_Xs_val_file:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ques_Xs_train, ques_Xs_test, ques_Ys_train, ques_Ys_test, ques_max_len=parse_audio_files(percentiles, ques_files_list, \"question\", Max_RNN)\n",
    "\n",
    "# print(len(ques_Xs_train), len(ques_Ys_train), len(ques_Xs_test), len(ques_Ys_test), \"Max Len: \", ques_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bx = np.concatenate( (dec_Xs_train,ques_Xs_train), axis = 0)\n",
    "# by = np.concatenate( (dec_Ys_train,ques_Ys_train), axis = 0)\n",
    "\n",
    "bx = np.concatenate( (dec_Xs_train_file,ques_Xs_train_file), axis = 0)\n",
    "by = np.concatenate( (dec_Ys_train_file,ques_Ys_train_file), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bx_val = np.concatenate( (dec_Xs_val,ques_Xs_val), axis = 0)\n",
    "# by_val = np.concatenate( (dec_Ys_val,ques_Ys_val), axis = 0)\n",
    "\n",
    "bx_val = np.concatenate( (dec_Xs_val_file,ques_Xs_val_file), axis = 0)\n",
    "by_val = np.concatenate( (dec_Ys_val_file,ques_Ys_val_file), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = bx.shape[0]\n",
    "suffle_n = np.random.permutation(n)\n",
    "\n",
    "bx = bx[suffle_n]\n",
    "by = by[suffle_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = bx_val.shape[0]\n",
    "suffle_n = np.random.permutation(n)\n",
    "\n",
    "bx_val = bx_val[suffle_n]\n",
    "by_val = by_val[suffle_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 1000)              1623000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 1,625,002\n",
      "Trainable params: 1,625,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24888 samples, validate on 1428 samples\n",
      "Epoch 1/20\n",
      "24888/24888 [==============================] - 422s 17ms/step - loss: 0.1198 - acc: 0.9462 - val_loss: 0.0536 - val_acc: 0.9832\n",
      "Epoch 2/20\n",
      "24888/24888 [==============================] - 401s 16ms/step - loss: 0.0340 - acc: 0.9879 - val_loss: 0.0570 - val_acc: 0.9776\n",
      "Epoch 3/20\n",
      "24888/24888 [==============================] - 401s 16ms/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.0437 - val_acc: 0.9860\n",
      "Epoch 4/20\n",
      "24888/24888 [==============================] - 402s 16ms/step - loss: 0.0242 - acc: 0.9916 - val_loss: 0.0524 - val_acc: 0.9832\n",
      "Epoch 5/20\n",
      "24888/24888 [==============================] - 395s 16ms/step - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0471 - val_acc: 0.9860\n",
      "Epoch 6/20\n",
      "24888/24888 [==============================] - 400s 16ms/step - loss: 0.0247 - acc: 0.9908 - val_loss: 0.0555 - val_acc: 0.9811\n",
      "Epoch 7/20\n",
      "24888/24888 [==============================] - 407s 16ms/step - loss: 0.0211 - acc: 0.9926 - val_loss: 0.0306 - val_acc: 0.9895\n",
      "Epoch 8/20\n",
      "24888/24888 [==============================] - 405s 16ms/step - loss: 0.0219 - acc: 0.9918 - val_loss: 0.0177 - val_acc: 0.9951\n",
      "Epoch 9/20\n",
      "24888/24888 [==============================] - 408s 16ms/step - loss: 0.0234 - acc: 0.9918 - val_loss: 0.0338 - val_acc: 0.9902\n",
      "Epoch 10/20\n",
      "24888/24888 [==============================] - 406s 16ms/step - loss: 0.0259 - acc: 0.9908 - val_loss: 0.0255 - val_acc: 0.9923\n",
      "Epoch 11/20\n",
      "24888/24888 [==============================] - 408s 16ms/step - loss: 0.0212 - acc: 0.9925 - val_loss: 0.0317 - val_acc: 0.9888\n",
      "Epoch 12/20\n",
      "24888/24888 [==============================] - 410s 16ms/step - loss: 0.0227 - acc: 0.9918 - val_loss: 0.0390 - val_acc: 0.9888\n",
      "Epoch 13/20\n",
      "24888/24888 [==============================] - 408s 16ms/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.0639 - val_acc: 0.9818\n",
      "Epoch 14/20\n",
      "24888/24888 [==============================] - 406s 16ms/step - loss: 0.0150 - acc: 0.9948 - val_loss: 0.0402 - val_acc: 0.9874\n",
      "Epoch 15/20\n",
      "24888/24888 [==============================] - 404s 16ms/step - loss: 0.0167 - acc: 0.9939 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 16/20\n",
      "24888/24888 [==============================] - 406s 16ms/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.0752 - val_acc: 0.9699\n",
      "Epoch 17/20\n",
      "24888/24888 [==============================] - 408s 16ms/step - loss: 0.0254 - acc: 0.9909 - val_loss: 0.0164 - val_acc: 0.9923\n",
      "Epoch 18/20\n",
      "24888/24888 [==============================] - 409s 16ms/step - loss: 0.0243 - acc: 0.9918 - val_loss: 0.0327 - val_acc: 0.9867\n",
      "Epoch 19/20\n",
      "24888/24888 [==============================] - 409s 16ms/step - loss: 0.0156 - acc: 0.9939 - val_loss: 0.0348 - val_acc: 0.9867\n",
      "Epoch 20/20\n",
      "24888/24888 [==============================] - 409s 16ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0834 - val_acc: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9216d4b0b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max_RNN = 1500\n",
    "\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=False), input_shape=(Max_RNN,40)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(bx, by, validation_data = (bx_val, by_val), shuffle=True, nb_epoch=20, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "bx_test = np.concatenate( (dec_Xs_test_file, ques_Xs_test_file), axis = 0)\n",
    "by_test = np.concatenate( (dec_Ys_test_file, ques_Ys_test_file), axis = 0)\n",
    "\n",
    "\n",
    "scores = model.evaluate(bx_test, by_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(fp)\n",
    "        print(X.shape)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def plot_waves(raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,10), dpi = 900)\n",
    "    for f in raw_sounds:\n",
    "        plt.subplot(2,5,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=22050)\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 1: Waveplot',x=0.5, y=0.95,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,10), dpi = 900)\n",
    "    for f in raw_sounds:\n",
    "        plt.subplot(2,5,i)\n",
    "        specgram(np.array(f), Fs=22050)\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.95,fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_sounds_ques = load_sound_files(ques_files_list[:5])\n",
    "plot_waves(raw_sounds_ques)\n",
    "# plot_specgram(raw_sounds_ques)\n",
    "# raw_sounds_dec = load_sound_files(dec_files_list[:5])\n",
    "# plot_waves(raw_sounds_dec)\n",
    "# plot_specgram(raw_sounds_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(raw_sounds_ques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sounds_dec = load_sound_files(dec_files_list[:5])\n",
    "plot_waves(raw_sounds_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(raw_sounds_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename = \"Corpus/A_man_bought_a_car_in_Paris-DC-2.wav\"\n",
    "mfccs=extract_mfcc(sample_filename)\n",
    "print (\"MFCSS  = \", len(mfccs))\n",
    "data_points, _ = librosa.load(sample_filename)\n",
    "print( \"IN: Initial Data Points =\", len(data_points), np.shape(data_points))\n",
    "print (\"OUT: Total features =\",  mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs=np.pad(mfccs, [(0, 0), (0, RNN_LENGTH-len(mfccs[0]))], mode='constant')\n",
    "print(mfccs.shape)\n",
    "mfccs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulted_list=parse_audio_files(filename_list)\n",
    "len(resulted_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_sounds)\n",
    "for i in range(len(raw_sounds)):\n",
    "    print(raw_sounds[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    print (\"Features :\",len(X), X.shape, \"sampled at \", sample_rate, \"hz\")\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "                mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
    "                ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "                features = np.vstack([features,ext_features])\n",
    "                labels = np.append(labels, fn.split('fold')[1].split('-')[1])\n",
    "            except:\n",
    "                print(\"Error processing \" + fn + \" - skipping\")\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    mydir = os.path.join(os.getcwd(), path)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.makedirs(mydir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
