{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCFG Parsing using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [my](http://damir.cavar.me/) own NLTK notebooks and [Michael Elhadad](https://www.cs.bgu.ac.il/~elhadad/)'s notebook *[Constituent-based Syntactic Parsing with NLTK](https://www.cs.bgu.ac.il/~elhadad/nlp16/nltk-pcfg.html)*.  See for related material:\n",
    "\n",
    "1. [Python Parsing with NLTK](https://github.com/dcavar/python-tutorial-for-ipython/blob/master/notebooks/Python%20Parsing%20with%20NLTK.ipynb)\n",
    "1. [Python Parsing with NLTK and Foma](https://github.com/dcavar/python-tutorial-for-ipython/blob/master/notebooks/Python%20Parsing%20with%20NLTK%20and%20Foma.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(C) 2018-2019 by [Damir Cavar](http://damir.cavar.me/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial related to the discussion of grammar engineering and parsing in the class Alternative Syntactic Theories and Advanced Natural Language Processing taught at Indiana University in Spring 2017 and Fall 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples presuppose an installed Python 3.x [NLTK](https://www.nltk.org/) module with all the dependent modules and packages, as well as the [data set for NLTK](https://www.nltk.org/data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Penn-Treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the NLTK *corpus* module to read and use the different corpora in the NLTK [data set](https://www.nltk.org/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the portion of the Penn Treebank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb = nltk.corpus.treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus consists of a collection of files. Each file has an ID (file name). You can print the IDs using the *fileids* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', 'wsj_0005.mrg', 'wsj_0006.mrg', 'wsj_0007.mrg', 'wsj_0008.mrg', 'wsj_0009.mrg', 'wsj_0010.mrg', 'wsj_0011.mrg', 'wsj_0012.mrg', 'wsj_0013.mrg', 'wsj_0014.mrg', 'wsj_0015.mrg', 'wsj_0016.mrg', 'wsj_0017.mrg', 'wsj_0018.mrg', 'wsj_0019.mrg', 'wsj_0020.mrg', 'wsj_0021.mrg', 'wsj_0022.mrg', 'wsj_0023.mrg', 'wsj_0024.mrg', 'wsj_0025.mrg', 'wsj_0026.mrg', 'wsj_0027.mrg', 'wsj_0028.mrg', 'wsj_0029.mrg', 'wsj_0030.mrg', 'wsj_0031.mrg', 'wsj_0032.mrg', 'wsj_0033.mrg', 'wsj_0034.mrg', 'wsj_0035.mrg', 'wsj_0036.mrg', 'wsj_0037.mrg', 'wsj_0038.mrg', 'wsj_0039.mrg', 'wsj_0040.mrg', 'wsj_0041.mrg', 'wsj_0042.mrg', 'wsj_0043.mrg', 'wsj_0044.mrg', 'wsj_0045.mrg', 'wsj_0046.mrg', 'wsj_0047.mrg', 'wsj_0048.mrg', 'wsj_0049.mrg', 'wsj_0050.mrg', 'wsj_0051.mrg', 'wsj_0052.mrg', 'wsj_0053.mrg', 'wsj_0054.mrg', 'wsj_0055.mrg', 'wsj_0056.mrg', 'wsj_0057.mrg', 'wsj_0058.mrg', 'wsj_0059.mrg', 'wsj_0060.mrg', 'wsj_0061.mrg', 'wsj_0062.mrg', 'wsj_0063.mrg', 'wsj_0064.mrg', 'wsj_0065.mrg', 'wsj_0066.mrg', 'wsj_0067.mrg', 'wsj_0068.mrg', 'wsj_0069.mrg', 'wsj_0070.mrg', 'wsj_0071.mrg', 'wsj_0072.mrg', 'wsj_0073.mrg', 'wsj_0074.mrg', 'wsj_0075.mrg', 'wsj_0076.mrg', 'wsj_0077.mrg', 'wsj_0078.mrg', 'wsj_0079.mrg', 'wsj_0080.mrg', 'wsj_0081.mrg', 'wsj_0082.mrg', 'wsj_0083.mrg', 'wsj_0084.mrg', 'wsj_0085.mrg', 'wsj_0086.mrg', 'wsj_0087.mrg', 'wsj_0088.mrg', 'wsj_0089.mrg', 'wsj_0090.mrg', 'wsj_0091.mrg', 'wsj_0092.mrg', 'wsj_0093.mrg', 'wsj_0094.mrg', 'wsj_0095.mrg', 'wsj_0096.mrg', 'wsj_0097.mrg', 'wsj_0098.mrg', 'wsj_0099.mrg', 'wsj_0100.mrg', 'wsj_0101.mrg', 'wsj_0102.mrg', 'wsj_0103.mrg', 'wsj_0104.mrg', 'wsj_0105.mrg', 'wsj_0106.mrg', 'wsj_0107.mrg', 'wsj_0108.mrg', 'wsj_0109.mrg', 'wsj_0110.mrg', 'wsj_0111.mrg', 'wsj_0112.mrg', 'wsj_0113.mrg', 'wsj_0114.mrg', 'wsj_0115.mrg', 'wsj_0116.mrg', 'wsj_0117.mrg', 'wsj_0118.mrg', 'wsj_0119.mrg', 'wsj_0120.mrg', 'wsj_0121.mrg', 'wsj_0122.mrg', 'wsj_0123.mrg', 'wsj_0124.mrg', 'wsj_0125.mrg', 'wsj_0126.mrg', 'wsj_0127.mrg', 'wsj_0128.mrg', 'wsj_0129.mrg', 'wsj_0130.mrg', 'wsj_0131.mrg', 'wsj_0132.mrg', 'wsj_0133.mrg', 'wsj_0134.mrg', 'wsj_0135.mrg', 'wsj_0136.mrg', 'wsj_0137.mrg', 'wsj_0138.mrg', 'wsj_0139.mrg', 'wsj_0140.mrg', 'wsj_0141.mrg', 'wsj_0142.mrg', 'wsj_0143.mrg', 'wsj_0144.mrg', 'wsj_0145.mrg', 'wsj_0146.mrg', 'wsj_0147.mrg', 'wsj_0148.mrg', 'wsj_0149.mrg', 'wsj_0150.mrg', 'wsj_0151.mrg', 'wsj_0152.mrg', 'wsj_0153.mrg', 'wsj_0154.mrg', 'wsj_0155.mrg', 'wsj_0156.mrg', 'wsj_0157.mrg', 'wsj_0158.mrg', 'wsj_0159.mrg', 'wsj_0160.mrg', 'wsj_0161.mrg', 'wsj_0162.mrg', 'wsj_0163.mrg', 'wsj_0164.mrg', 'wsj_0165.mrg', 'wsj_0166.mrg', 'wsj_0167.mrg', 'wsj_0168.mrg', 'wsj_0169.mrg', 'wsj_0170.mrg', 'wsj_0171.mrg', 'wsj_0172.mrg', 'wsj_0173.mrg', 'wsj_0174.mrg', 'wsj_0175.mrg', 'wsj_0176.mrg', 'wsj_0177.mrg', 'wsj_0178.mrg', 'wsj_0179.mrg', 'wsj_0180.mrg', 'wsj_0181.mrg', 'wsj_0182.mrg', 'wsj_0183.mrg', 'wsj_0184.mrg', 'wsj_0185.mrg', 'wsj_0186.mrg', 'wsj_0187.mrg', 'wsj_0188.mrg', 'wsj_0189.mrg', 'wsj_0190.mrg', 'wsj_0191.mrg', 'wsj_0192.mrg', 'wsj_0193.mrg', 'wsj_0194.mrg', 'wsj_0195.mrg', 'wsj_0196.mrg', 'wsj_0197.mrg', 'wsj_0198.mrg', 'wsj_0199.mrg']\n"
     ]
    }
   ],
   "source": [
    "print(ptb.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the content of a particular file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( (S \n",
      "    (NP-SBJ \n",
      "      (NP (NNP Pierre) (NNP Vinken) )\n",
      "      (, ,) \n",
      "      (ADJP \n",
      "        (NP (CD 61) (NNS years) )\n",
      "        (JJ old) )\n",
      "      (, ,) )\n",
      "    (VP (MD will) \n",
      "      (VP (VB join) \n",
      "        (NP (DT the) (NN board) )\n",
      "        (PP-CLR (IN as) \n",
      "          (NP (DT a) (JJ nonexecutive) (NN director) ))\n",
      "        (NP-TMP (NNP Nov.) (CD 29) )))\n",
      "    (. .) ))\n",
      "( (S \n",
      "    (NP-SBJ (NNP Mr.) (NNP Vinken) )\n",
      "    (VP (VBZ is) \n",
      "      (NP-PRD \n",
      "        (NP (NN chairman) )\n",
      "        (PP (IN of) \n",
      "          (NP \n",
      "            (NP (NNP Elsevier) (NNP N.V.) )\n",
      "            (, ,) \n",
      "            (NP (DT the) (NNP Dutch) (VBG publishing) (NN group) )))))\n",
      "    (. .) ))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ptb.raw('wsj_0001.mrg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the file *wsj_0001.mrg* contains two sentence trees. You can access each sentence tree individually. Here we print out the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "print(ptb.parsed_sents('wsj_0001.mrg')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the following code we print the second tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ (NNP Mr.) (NNP Vinken))\n",
      "  (VP\n",
      "    (VBZ is)\n",
      "    (NP-PRD\n",
      "      (NP (NN chairman))\n",
      "      (PP\n",
      "        (IN of)\n",
      "        (NP\n",
      "          (NP (NNP Elsevier) (NNP N.V.))\n",
      "          (, ,)\n",
      "          (NP (DT the) (NNP Dutch) (VBG publishing) (NN group))))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "print(ptb.parsed_sents('wsj_0001.mrg')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the tree structure as a graphic, you can apply the *draw()* method to the particular tree. The following code will open up a window with the drawing of the first tree in the file *wsj_0001.mrg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb.parsed_sents('wsj_0001.mrg')[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the menu of the window you can export the drawing of the tree as a Postscript file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK allows you to define your own tree using the bracketed notation and the *[Tree](http://www.nltk.org/_modules/nltk/tree.html)* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a string variable with a syntactic tree and create a Tree object by applying the *fromstring* method from the *Tree* class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = \"(S (NP (NN cats ) ) (VP (V chase ) (NP (NN mice ) ) ))\"\n",
    "myTree = Tree.fromstring(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the tree in bracketed notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NN cats)) (VP (V chase) (NP (NN mice))))\n"
     ]
    }
   ],
   "source": [
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internal representation of the tree looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [Tree('NP', [Tree('NN', ['cats'])]), Tree('VP', [Tree('V', ['chase']), Tree('NP', [Tree('NN', ['mice'])])])])\n"
     ]
    }
   ],
   "source": [
    "print(myTree.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree can be written in LaTeX format for the *qtree* package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Tree [.S [.NP [.NN cats ] ] [.VP [.V chase ] [.NP [.NN mice ] ] ] ]\n"
     ]
    }
   ],
   "source": [
    "print(myTree.pformat_latex_qtree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw the tree by applying the *draw()* method to the tree object. The following code will open up a window with the drawing of the corresponding tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the label of a tree or subtrees using the *label* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "print(myTree.label())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A daughter of the root node of the tree can be accessed using the list index notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP (NN cats))\n",
      "(VP (V chase) (NP (NN mice)))\n"
     ]
    }
   ],
   "source": [
    "print(myTree[0])\n",
    "print(myTree[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the label of these subtrees by applying the *label* method to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myTree[0].label())\n",
    "print(myTree[1].label())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can traverse the tree using these bracketed index operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP (NN cats))\n",
      "(NN cats)\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "print(myTree[0])\n",
    "print(myTree[0,0])\n",
    "print(myTree[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sections of the tree can be modified or replaced using the index notation. We replace the subject *(NN cats)* with *(NN dogs)* in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NN dogs)) (VP (V chase) (NP (NN mice))))\n"
     ]
    }
   ],
   "source": [
    "myTree[0,0] = Tree.fromstring('(NN dogs)')\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various details about the tree can be accessed. We can extract the leaves of the tree using the *leaves* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'chase', 'mice']\n"
     ]
    }
   ],
   "source": [
    "print(myTree.leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the height of a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(myTree.height())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For specific purposes and some specific algorithms one might want to convert the tree to remove all unary relations between symbols. To collapse for example *(NP (NP (NN dogs )))* to *(NP+NP (NN cats ))*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP+NP (NN cats)) (VP (V chase) (NP (NN mice))))\n"
     ]
    }
   ],
   "source": [
    "trees2 = \"(S (NP (NP (NN cats ) ) ) (VP (V chase ) (NP (NN mice ) ) ))\"\n",
    "myTree2 = Tree.fromstring(trees2)\n",
    "myTree2.collapse_unary()\n",
    "print(myTree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a tree to Chomsky Normal Form as well. In the following tree we have a subject NP branching into three daughter nodes. This is converted to a binary branching structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (NP (DET the) (NP|<JJ-NN> (JJ big) (NN cats))))\n",
      "  (VP (V chase) (NP (NN mice))))\n"
     ]
    }
   ],
   "source": [
    "trees2 = \"(S (NP (NP (DET the ) (JJ big ) (NN cats ) ) ) (VP (V chase ) (NP (NN mice ) ) ))\"\n",
    "myTree2 = Tree.fromstring(trees2)\n",
    "myTree2.chomsky_normal_form()\n",
    "print(myTree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate all production rules for a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " NP -> NN,\n",
       " NN -> 'dogs',\n",
       " VP -> V NP,\n",
       " V -> 'chase',\n",
       " NP -> NN,\n",
       " NN -> 'mice']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees can contain nodes that are complex objects. Nodes do not have to be strings. In the following code we replace the root node of our tree with a tuple of string and integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('S', 3) (NP (NN dogs)) (VP (V chase) (NP (NN mice))))\n"
     ]
    }
   ],
   "source": [
    "myTree.set_label( ('S', 3) )\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic rules or trees can be defined in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP DET N) (p=0.5)\n"
     ]
    }
   ],
   "source": [
    "pt = nltk.tree.ProbabilisticTree('NP', ['DET', 'N'], prob=0.5)\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections (see links to the other notebooks above), we have seen how CFGs can be defined, read from a file, or used in a parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCFG rules are defined in the same way. In addition a probability is assigned to each right-hand side of a rule. All probabilities for one particular left-hand side have to sum up to 1. The following code imports the PCFG class from NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PCFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcfg1 = PCFG.fromstring(\"\"\"\n",
    "    S -> NP VP [1.0]\n",
    "    NP -> Det N [0.5] | NP PP [0.25] | N [0.25]\n",
    "    PP -> P NP [1.0]\n",
    "    VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
    "    N -> 'woman' [0.3] | 'man' [0.3] | 'telescope' [0.3] | 'mixer' [0.1]\n",
    "    Det -> 'the' [0.6] | 'a' [0.2] | 'my' [0.2]\n",
    "    V -> 'killed' [0.35] | 'saw' [0.65]\n",
    "    P -> 'with' [0.61] | 'under' [0.39]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the productions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pcfg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import the portion of the Penn Treebank as *treebank*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop over all files, read the sentences in, extract all production rules from them, and aggregate the production rules in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = []\n",
    "for t in treebank.fileids()[:2]:\n",
    "    for x in treebank.parsed_sents(t):\n",
    "        productions += x.productions()\n",
    "print(productions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to induce the PCFG, we need to define a *Nonterminal* object with the start symbol as label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Nonterminal\n",
    "S = Nonterminal('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now induce the PCFG using the *Nonterminal* start symbol and the list of production rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can normalize the trees by collapsing unary branches and converting them to Chomsky Normal Form before we extract the production rules and induce the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = []\n",
    "for t in treebank.fileids()[:2]:\n",
    "    for x in treebank.parsed_sents(t):\n",
    "        x.collapse_unary(collapsePOS = False)\n",
    "        x.chomsky_normal_form(horzMarkov = 2)\n",
    "        productions += x.productions()\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with PCFGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides various parser implementations. One that implements the Viterbi CKY n-best parses over a PCFG is available in the [parse.viterbi](http://www.nltk.org/_modules/nltk/parse/viterbi.html) module. (See [Michael Elhadad](https://www.cs.bgu.ac.il/~elhadad/)'s notebook *[Constituent-based Syntactic Parsing with NLTK](https://www.cs.bgu.ac.il/~elhadad/nlp16/nltk-pcfg.html)* for more details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Parse sentence using induced grammar:\")\n",
    "\n",
    "parser = nltk.pchart.InsideChartParser(grammar)\n",
    "parser.trace(3)\n",
    "\n",
    "sent = treebank.parsed_sents('wsj_0001.mrg')[0].leaves()\n",
    "print(sent)\n",
    "\n",
    "for parse in parser.parse(sent):\n",
    "  print(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other parsers are defined in the *nltk.parse* module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "from nltk import tokenize\n",
    "from nltk.grammar import toy_pcfg1\n",
    "from nltk.parse import pchart\n",
    "from nltk.parse import ViterbiParser\n",
    "\n",
    "demos = [('I saw John with my telescope', toy_pcfg1)]\n",
    "sent, grammar = demos[0]\n",
    "\n",
    "# Tokenize the sentence.\n",
    "tokens = sent.split()\n",
    "\n",
    "# Define a list of parsers.  We'll use all parsers.\n",
    "parsers = [\n",
    "ViterbiParser(grammar),\n",
    "pchart.InsideChartParser(grammar),\n",
    "pchart.RandomChartParser(grammar),\n",
    "pchart.UnsortedChartParser(grammar),\n",
    "pchart.LongestChartParser(grammar),\n",
    "pchart.InsideChartParser(grammar, beam_size = len(tokens)+1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop over the different parsers and compare the output and performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the parsers on the tokenized sentence.\n",
    "from functools import reduce\n",
    "times = []\n",
    "average_p = []\n",
    "num_parses = []\n",
    "all_parses = {}\n",
    "for parser in parsers:\n",
    "    print('\\ns: %s\\nparser: %s\\ngrammar: %s' % (sent,parser,grammar))\n",
    "    parser.trace(3)\n",
    "    t = time.time()\n",
    "    parses = parser.parse_all(tokens)\n",
    "    times.append(time.time()-t)\n",
    "    if parses: \n",
    "        lp = len(parses)\n",
    "        p = reduce(lambda a,b:a+b.prob(), parses, 0.0)\n",
    "    else: \n",
    "        p = 0\n",
    "    average_p.append(p)\n",
    "    num_parses.append(len(parses))\n",
    "    for p in parses: \n",
    "        all_parses[p.freeze()] = 1\n",
    "\n",
    "# Print summary statistics\n",
    "print()\n",
    "print('-------------------------+------------------------------------------')\n",
    "print('   Parser           Beam | Time (secs)   # Parses   Average P(parse)')\n",
    "print('-------------------------+------------------------------------------')\n",
    "for i in range(len(parsers)):\n",
    "    print('%19s %4d |%11.4f%11d%19.14f' % (parsers[i].__class__.__name__,\n",
    "      getattr(parsers[0], \"beam_size\", 0),\n",
    "      times[i], \n",
    "      num_parses[i], \n",
    "      average_p[i]))\n",
    "parses = all_parses.keys()\n",
    "if parses: \n",
    "    p = reduce(lambda a,b:a+b.prob(), parses, 0)/len(parses)\n",
    "else: \n",
    "    p = 0\n",
    "print('-------------------------+------------------------------------------')\n",
    "print('%19s      |%11s%11d%19.14f' % ('(All Parses)', 'n/a', len(parses), p))\n",
    "print()\n",
    "\n",
    "for parse in parses:\n",
    "    print(parse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 2018 by [Damir Cavar](http://damir.cavar.me/) - [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)). Parts of the code are taken from [Michael Elhadad](https://www.cs.bgu.ac.il/~elhadad/)'s notebook *[Constituent-based Syntactic Parsing with NLTK](https://www.cs.bgu.ac.il/~elhadad/nlp16/nltk-pcfg.html)*. Please consult him for details about the copyright."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
